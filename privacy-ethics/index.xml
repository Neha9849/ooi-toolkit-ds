<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data Privacy &amp; Ethics on UNICEF Data Science &amp; A.I. Toolkit</title><link>https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/</link><description>Recent content in Data Privacy &amp; Ethics on UNICEF Data Science &amp; A.I. Toolkit</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Creative Commons BY-SA 4.0. Site theme adapted from UNICEF Inventory theme.</copyright><atom:link href="https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/index.xml" rel="self" type="application/rss+xml"/><item><title>AI Ethics &amp; Transparency Roadmap - Template</title><link>https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/milestone-roadmap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/milestone-roadmap/</guid><description>How do you document your machine learning development process? This guide shares transparency best practices.
This is your at a glance version of the document. Details and resources are below.
Milestone 1: Understanding the Data Flow Data Ecosystem Map Information Sharing Protocol Milestone 2: Understanding the Algorithm Dataset Structure Common Traps Mitigations Milestone 3: Sharing the Model Model Card Created Understanding Data Flow Primary Goal: Create documentation that ensures you know what data you&amp;rsquo;re using and how you plan on sharing it.</description></item><item><title>Common traps to avoid when building AI systems</title><link>https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/traps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/traps/</guid><description>Assessing common mistakes that lead to unintended side effects. Information summarized from Fairness and Abstraction in Sociotechnical Systems, a paper published at the 2019 ACM Conference on Fairness, Accountability, and Transparency.
Framing Trap Failure to model the entire system over which a social criterion, such as fairness, will be enforced.
For this trap, we will want to look at our outcome variables. Are these variables a proxy of the actual outcome you wish to achieve?</description></item><item><title>Machine Learning Model Card</title><link>https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/model-card/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/model-card/</guid><description>The following is an editable version of the model card proposed in arxiv.org/abs/1810.03993.
Model details Basic information about the model.
Person or organization developing model Date of last update Model version Model type (information about training algorithms, parameters, fairness constraints or other applied approaches, and features) Paper or other resource for more information Citation details License Maintainer contact details Intended use Use cases that were envisioned during development.</description></item><item><title>Policy guidance on AI for children (via unicef.org)</title><link>https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/policy-guidance-children/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://unicef.github.io/ooi-toolkit-ds/privacy-ethics/policy-guidance-children/</guid><description>As part of our AI for children project, UNICEF has developed this policy guidance to promote children&amp;rsquo;s rights in government and private sector AI policies and practices, and to raise awareness of how AI systems can uphold or undermine these rights. The policy guidance explores AI systems, and considers the ways in which they impact children.
Read in full: unicef.org/globalinsight/reports/policy-guidance-ai-children Drawing on the Convention on the Rights of the Child, the guidance offers nine requirements for child-centered AI:</description></item></channel></rss>