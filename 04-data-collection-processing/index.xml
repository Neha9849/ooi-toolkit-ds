<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data Collection and Processing on UNICEF Data Science &amp; A.I. Toolkit</title><link>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/</link><description>Recent content in Data Collection and Processing on UNICEF Data Science &amp; A.I. Toolkit</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Creative Commons BY-SA 4.0. Site theme adapted from UNICEF Inventory theme.</copyright><atom:link href="https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/index.xml" rel="self" type="application/rss+xml"/><item><title>Data Governance</title><link>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-governance.en.adoc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-governance.en.adoc/</guid><description>Data governance is a critical component of a sustainable and scalable AI project. Data governance is defined as a collection of processes, roles, policies, standards and metrics that ensure the effective and efficient use of information. Good data governance establishes processes and responsibilities ensuring data quality and security. Essentially, data governance defines who can act on the data, upon what data, in which situations and with what methods.
Attribution:
Evren Eryurek, et al.</description></item><item><title>Data Pre-processing</title><link>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-preprocessing.en.adoc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-preprocessing.en.adoc/</guid><description>Data pre-processing has to do with the process of managing, analyzing, filtering, transforming, encoding and preparing data to be usefully processed by the machine. This is typically one of the most time-consuming aspects of the data science process. Any decisions made by the data scientist in the data pre-processing stage can have important impacts in subsequent model development and, even, deployment stages. Therefore, it is important to document analytical decisions made in this stage, whether in the code or through a documenting tool, to trace the lineage of the data from the original data source, when the data is in its raw form, to the model training and development stage.</description></item><item><title>Data Quality</title><link>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-quality.en.adoc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-quality.en.adoc/</guid><description>Data quality is a critical concern for AI projects. Poor data quality can bias prediction results and mislead users. There are six key areas of data quality:
Accuracy: how well does the data reflect reality?
Completeness: is the data comprehensive or not missing value entries in unexpected instances?
Consistency: does information stored in one place match the information stored in another place?
Timeliness: is data available when needed?
Validity: is data in a specific format?</description></item><item><title>Feature Engineering</title><link>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/feature-engineering.en.adoc-copy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/feature-engineering.en.adoc-copy/</guid><description>Feature engineering is related to data pre-processing but is more closely related to the modeling process. Feature engineering refers to when model inputs or features are generated that are then incorporated into a model for training. Typically, this means adjusting and reworking the predictors to enable models to better uncover predictor-response relationships. The engineering involves the steps taken to improve model performance by generating the appropriate features. Since we may not know in advance what adjustments or re-adjustments of the features are required to improve model performance, the re-working of predictors can be experimental in nature requiring experience and tools to find predictor representations.</description></item><item><title>Missing Data</title><link>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/missing-data.en.adoc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/missing-data.en.adoc/</guid><description>Handling missing values can be a component of data pre-processing as well as feature engineering. Missing values can occur for several reasons including structural deficiencies in the data (namely, deliberate omission in the data collection or data generating process), random occurrences, or specific reasons.
A structural deficiency would be the case of a missing component of a predictor omitted from the data. Typically, these cases could be resolved once the necessary component is identified.</description></item></channel></rss>