<!doctype html><html lang=en-us><head><meta charset=utf-8><title>UNICEF Data Science & A.I. Toolkit</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.96.0"><meta name=description content="UNICEF Data Science & A.I. Toolkit - UNICEF Data Science & A.I. Toolkit "><link rel=stylesheet href=https://unicef.github.io/ooi-toolkit-ds/plugins/bootstrap/bootstrap.min.css><link rel=stylesheet href=https://unicef.github.io/ooi-toolkit-ds/plugins/themify-icons/themify-icons.css><link rel=stylesheet href=https://unicef.github.io/ooi-toolkit-ds/plugins/drone-dpgtoolkit-icons/icons.css><link rel=icon href=https://unicef.github.io/ooi-toolkit-ds/images/favicon.png type=image/x-icon><link href="https://fonts.googleapis.com/css?family=Open%2bSans:300,400,700&display=swap" rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.9.359/pdf.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.9.3/html2pdf.bundle.js></script>
<script src=https://kit.fontawesome.com/9196e0632a.js crossorigin=anonymous></script><style>:root{--primary-color:#1CABE2;--body-color:#D8D1C9;--text-color:#777779;--text-color-dark:#374EA2;--text-title-color:#ffffff;--white-color:#ffffff;--light-color:#f8f9fa;--font-family:Open+Sans}</style><link href=https://unicef.github.io/ooi-toolkit-ds/css/style.min.css rel=stylesheet media=screen><script src=https://unicef.github.io/ooi-toolkit-ds/plugins/jquery/jquery-1.12.4.js></script>
<script src=https://unicef.github.io/ooi-toolkit-ds/plugins/jquery/jquery-ui.js></script>
<script src=https://unicef.github.io/ooi-toolkit-ds/plugins/bootstrap/bootstrap.min.js></script>
<script src=https://unpkg.com/@popperjs/core@2></script>
<script src=https://unicef.github.io/ooi-toolkit-ds/plugins/match-height/jquery.matchHeight-min.js></script><meta name=twitter:title content="UNICEF Data Science & A.I. Toolkit"><meta name=twitter:description content="A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation."><meta property="og:title" content="UNICEF Data Science & A.I. Toolkit"><meta property="og:description" content="A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation."><meta property="og:type" content="website"><meta property="og:url" content="https://unicef.github.io/ooi-toolkit-ds/"><meta name=twitter:card content="summary"><meta name=twitter:title content="UNICEF Data Science & A.I. Toolkit"><meta name=twitter:description content="A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation."></head><body><header class="banner overlay bg-cover" data-background=https://unicef.github.io/ooi-toolkit-ds/images/banner.jpg><nav class="navbar navbar-expand-md navbar-dark" style=background-color:transparent><div class="container px-2 px-md-0 navigation-bar"><div id=site-brand><a class="navbar-brand px-2" href=https://www.unicef.org/><div class=text-center><img class="img-fluid d-inline" src=https://unicef.github.io/ooi-toolkit-ds/images/unicef-logo.png alt="UNICEF Data Science & A.I. Toolkit"> <a class="text-white d-block" href=/ooi-toolkit-ds>UNICEF Data Science & A.I. Toolkit</a></div></a></div><button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation aria-controls=navigation aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse text-center" id=navigation><ul class="navbar-nav ml-auto"><li class=nav-item><a class="nav-link text-white" href=https://unicef.github.io/ooi-toolkit-ds/faq>FAQ</a></li><li class=nav-item><a class="nav-link text-white" href=https://unicef.github.io/ooi-toolkit-ds/pages>pages</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle text-white" href=# role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Toolkits</a><div class=dropdown-menu><a class=dropdown-item href=https://unicef.github.io/drone-4sdgtoolkit/>Drones</a>
<a class=dropdown-item href=https://unicef.github.io/inventory/>Open Source</a>
<a class=dropdown-item href=https://unicef.github.io/ooi-toolkit-software/>Software Development</a></div></li></ul></div></div><p class="text-white unicef-glob mx-3">Visit <a href=https://www.unicef.org/ class=text-white>UNICEF Global <i class="fas fa-angle-double-right"></i></a></p></nav><div class="container section"><div class=row><div class="col-lg-8 text-center mx-auto"><h1 class="text-white mb-3">UNICEF Data Science & A.I. Toolkit</h1><p class="text-white mb-4">A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation.</p><div class=position-relative><input id=search class=form-control placeholder="Have a question? Search the site here.">
<i class="ti-search search-icon"></i>
<script>$(function(){var e=[{value:"Alerts",label:"<p></p>",url:"https://unicef.github.io/ooi-toolkit-ds/alerts/"},{value:"Categories",label:"<p></p>",url:"https://unicef.github.io/ooi-toolkit-ds/categories/"},{value:"Data Collection and Processing",label:"<p>This toolkit will draw on considerations in data collection and processing for your data science project.\nData science naturally relies on collecting data from some source. Typically, data is generated by human activity, such as logs of activity on a web platform (for e.g., clicks, score records, etc.), recorded events (for e.g., visits to medical facilities, attendance at school, etc.), text scripts, visual images or audio recordings. Most data generated in this way is typically observational whereby the data collector has no control over the data generating process that occurs in the real world. Observational data is collected based on what is seen or heard by people or a computer passively observing some process.\nData can also be experimental, whereby data is collected in a controlled environment following a scientific method. Experimental data is not passively collected, but rather it is collected methodically to answer a specific question typically in a controlled setting. In experimental settings, a group of people or things are randomly assigned to treatment and control groups. For example, in drug trials, a treatment group is given some dosage of a drug, while a control group would be assigned a placebo. Experiments lend themselves best to cause-and-effect studies because assigned to treatment and control are randomized and therefore, latent confounding factors that might differentiate the groups can be controlled or explicitly identified. In contrast, cause-and-effect claims cannot be made readily with observational data unless all explicit and latent factors can be controlled for and there is some source of external source of variation that can be attributed directly to the effect (a challenging analytical task).1 Controlled experiments of this type are often used in A/B testing and user design testing.\nAnother consideration is whether the data is structured or unstructured. Structured data has a sense of order and is typically in a row-column structured framework such as spreadsheets or database tables. Unstructured data can be images, text scripts or audio files. Unstructured data can require additional processing to convert their attributes into structured data format for analysis methods.\nAttribution: 1Gerber, Alan S., and Donald P. Green. Field Experiments: Design, Analysis, and Interpretation. W.W. Norton, 2012.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/"},{value:"Data Governance",label:"<p>Data governance is a critical component of a sustainable and scalable AI project. Data governance is defined as a collection of processes, roles, policies, standards and metrics that ensure the effective and efficient use of information. Good data governance establishes processes and responsibilities ensuring data quality and security. Essentially, data governance defines who can act on the data, upon what data, in which situations and with what methods.\nAttribution:\nEvren Eryurek, et al. Data Governance: The Definitive Guide: People, Processes, and Tools to Operationalize Data Trustworthiness. O’Reilly Media, 2021.\nBuilding a data governance framework - Talend Data Integration. Talend. (n.d.). Retrieved from https://www.talend.com/resources/building-data-governance-framework/\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-governance.en.adoc/"},{value:"Data Pre-processing",label:"<p>Data pre-processing has to do with the process of managing, analyzing, filtering, transforming, encoding and preparing data to be usefully processed by the machine. This is typically one of the most time-consuming aspects of the data science process. Any decisions made by the data scientist in the data pre-processing stage can have important impacts in subsequent model development and, even, deployment stages. Therefore, it is important to document analytical decisions made in this stage, whether in the code or through a documenting tool, to trace the lineage of the data from the original data source, when the data is in its raw form, to the model training and development stage.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-preprocessing.en.adoc/"},{value:"Data Quality",label:"<p>Data quality is a critical concern for AI projects. Poor data quality can bias prediction results and mislead users. There are six key areas of data quality:\nAccuracy: how well does the data reflect reality?\nCompleteness: is the data comprehensive or not missing value entries in unexpected instances?\nConsistency: does information stored in one place match the information stored in another place?\nTimeliness: is data available when needed?\nValidity: is data in a specific format? Is it an unusable format? Does it follow business rules?\nUniqueness: Is the data instance the only instance in which the data appears in the sample?\nAttribution:\nSarfin, R. L., \u0026amp; Editor, P. (2021, May 12). Data Quality Dimensions: How do you measure up? (\u002b free scorecard). Precisely. Retrieved from https://www.precisely.com/blog/data-quality/data-quality-dimensions-measure\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-quality.en.adoc/"},{value:"Definitions",label:"<p>It is important to start with some definitions of the terminology used in this toolkit.\nData science is broadly defined as a craft or set of activities that involves working with large amounts of data, grappling with computational problems introduced by structure, size, messiness such as missing data, and the complexity of data, while attempting to solve a real-world problem. Product-oriented data science deals with everything from the data engineering and infrastructure for data collection and logging, to privacy considerations, to decisions around what data is user-facing, how and which data will be used to inform decisions, and how the data will be built back into the product.1\nArtificial intelligence (AI) is broadly defined as an effort to automate intellectual tasks normally performed by human beings. AI includes machine learning and deep learning as well as approaches that do not involve any learning. Symbolic AI, for example, is premised on the ability of programmers to hard code a sufficiently large number of rules for manipulating knowledge (this is also known as expert systems). Symbolic AI can serve well for logical, well-defined problems.2\nMachine learning (ML) is better suited for more complex and intractable problems, such as image classification, speech recognition, language translation and probabilistic anomaly detection. Machine learning is a subset of AI where data can be used to train computers to detect patterns and mimic human decision-making. A machine-learning system is trained rather than explicitly programmed. It’s presented with many examples relevant to a task, and it finds statistical structure in these examples that eventually allows the system to come up with rules for automating the task. Machine learning involves using algorithms to detect patterns in data and then use those learned patterns to predict an outcome on new data. Generally, this involves an iterative process and allows the machine learning system to determine predictions without being explicitly programmed.\nDeep learning is a subset of ML that can process a wider range of data resources including text, images and audio clips and typically requires less data preprocessing by humans. The “deep” part refers to learning successive layers of increasingly meaningful representations all learned from training data. The depth refers to the number of layers that contribute to a model of the data. In contrast, other approaches to machine learning tend to focus on learning only one or two layers of representations of the data; hence, they’re sometimes called shallow learning. In common-speak, the application of neural networks models refers to deep learning.\nNatural Language Processing (NLP) heavily leverages Machine Learning as well as Deep Learning to allow computers to interact with humans in their own natural language whether written or oral. NLP applications attempt to understand natural human communication, either written or spoken, and communicate in return with us using similar, natural language.\nRobotic Process Automation (RPA) is a type of automation that mimics the activity of a human when they carry out a structured, repetitive task or process, little judgement. It is generally rule based, can’t learn outside parameters, so not considered AI; however, RPA can be built with learning modules on complex tasks.\nFigure 1 diagram below depicts the AI ecosystem and the relationship between AI, ML, Deep Learning, NLP and RPA.\nFootnotes\n1 Schutt, Rachel, and Cathy O\u0026rsquo;Neil. Doing Data Science: Straight Talk from the Frontline. O\u0026rsquo;Reilly, 2013.\n2 Chollet François. Deep Learning with Python. Manning Publications, 2021.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/01-definitions/"},{value:"DownloadBtn",label:"<p></p>",url:"https://unicef.github.io/ooi-toolkit-ds/downloadbtn/"},{value:"Feature Engineering",label:"<p>Feature engineering is related to data pre-processing but is more closely related to the modeling process. Feature engineering refers to when model inputs or features are generated that are then incorporated into a model for training. Typically, this means adjusting and reworking the predictors to enable models to better uncover predictor-response relationships. The engineering involves the steps taken to improve model performance by generating the appropriate features. Since we may not know in advance what adjustments or re-adjustments of the features are required to improve model performance, the re-working of predictors can be experimental in nature requiring experience and tools to find predictor representations.\nFeature engineering can involve scaling (to scale numerical features so that they are in the same numerical scale) through standardization or normalization. Normalization involves mean scaling where the mean value of a particular feature is subtracted from each feature value. Standardization involves variance scaling where each feature has a mean value of zero and standard deviation of one.\nIf a feature can take on many values, it can be normalized with buckets. For example, if a feature is real-valued, ordinal, or integer valued, the values can be arranged into several different buckets. In some cases, features can be encoded into binary values (0 or 1, “Yes” or “No”, null or not null). The latter is typically the case with text features.\nAttribution:\nJohnson, K. and Max Kuhn. (2019, June 21). Feature engineering and selection: A practical approach for predictive models. Feature Engineering and Selection: A Practical Approach for Predictive Models. Retrieved from http://www.feat.engineering/\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/feature-engineering.en.adoc-copy/"},{value:"Machine Learning Lifecycle",label:"<p>This toolkit will emphasize the key aspects of the machine learning project lifecycle. This starts with scoping (defining the project), data collection and organization, model development and model deployment.\nFigure 2. The Machine Learning Lifecycle\nMachine learning projects typically start with scoping or defining the project. This includes deciding on the objectives of the project and what makes it a good candidate for a machine learning application.\nThen, it is defining the data and establishing a baseline. For example, if we can accurately predict an outcome 50% of the time just by flipping a coin, a model should, at least, do better than that. Features should be engineered attuned to the underlying characteristics of the data (for instance, different treatment of categorical versus numerical data types) and business-specific features related to the defined problem. Often, data exploration and data mining inform the data scientist about the features to craft. Moreover, we should ensure the data is labeled consistently in the case of a supervised learning problem.\nThe modeling process involves selecting an algorithm or model framework (what algorithmic framework makes sense for the problem and data at hand) and training the model to learn the representations in the input data that get us closer to the output data. Error analysis is performed to evaluate and improve the model. Typically, the model that best minimizes the error is selected for deployment. Often, modeling informs us about issues in the data organization and labeling, leading us to go back and fix issues in the data.\nDeployment is typically the final step in the process. Once the model is selected, and it is put into production, it should be continually monitored through error analysis and the entire system should be maintained to detect any changes in the underlying data distribution serving as inputs to the model. Over time, it is common for machine learning models to require maintenance and retraining (reverting back to model development and then re-deployed).\nAttribution\nNg, Andrew \u0026amp; Cristian Bartolomé Arámburu (n.d.). Introduction to Machine Learning in Production [MOOC]. Coursera DeepLearning.AI. https://www.coursera.org/learn/introduction-to-machine-learning-in-production\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/02-machine-learning-lifecycle/"},{value:"Missing Data",label:"<p>Handling missing values can be a component of data pre-processing as well as feature engineering. Missing values can occur for several reasons including structural deficiencies in the data (namely, deliberate omission in the data collection or data generating process), random occurrences, or specific reasons.\nA structural deficiency would be the case of a missing component of a predictor omitted from the data. Typically, these cases could be resolved once the necessary component is identified. For example, if a hypothetical dataset has some predictor variable where values are either “A” or “B” or missing, where most values are missing, it may be tempting to discard the predictor variable due to the high rate of missingness. However, discarding this predictor variable may inadvertently be throwing away valuable information since missing can be interpreted to mean not being “A” or “B”. A better recording of the predictor variable may be to replace the missing values with “Not A or B”.\nAnother reason for missing values may be due to random occurrences. This can be occurrences missing completely at random (“MCAR”) where the likelihood of a missing value is equal for all data points, both observed and unobserved. Missing values can be interpreted here as independent of the data generating process. This can also be an occurrence missing at random (“MAR”) where the likelihood of a missing value is not equal for all data points. In this case, the probability of a missing value depends on the observed data, but not unobserved data.\nA third reason for missingness can be due to specific reasons or missing not at random (“MNAR”). This often occurs in cross-sectional time series data where the same unit of observation (for example, patient in medical trial) drops out of a study. Measurements for this unit of observation will stop after dropping out of the study. The MNAR cases are difficult to handle in practice and data practitioners should seek to understand the nature of the missingness before applying a technique to correct for missingness since a misdiagnosis of missingness could lead to bias in model inference.\nAttribution:\nJohnson, K. and Max Kuhn. (2019, June 21). Feature engineering and selection: A practical approach for predictive models. Feature Engineering and Selection: A Practical Approach for Predictive Models. Retrieved from http://www.feat.engineering/\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/missing-data.en.adoc/"},{value:"Scoping",label:"<p>Scoping has to do with deciding on the objectives of the project and what makes it a good candidate for a machine learning or artificial intelligence application. Scoping can seem to be the most trivial aspect of a project, yet it involves the most fundamental part in initiating a project. There are a few questions a project team should ask before initiating a data problem:\n  Why is the problem important?\n  Who does the problem affect?\n  What if we don’t have the right data to solve the problem?\n  When is the project over?\n  What if we don’t like the results?\n  Attribution: Gutman, A. J., \u0026amp; Goldmeier, J. (2021). Becoming a data head: How to think, speak, and understand data science, statistics, and Machine Learning. John Wiley \u0026amp; Sons.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/03-scoping/"},{value:"UNICEF Data Science \u0026 A.I. Toolkit",label:"<p></p>",url:"https://unicef.github.io/ooi-toolkit-ds/"},{value:"What if we don’t have the right data to solve the problem?",label:"<p>This has to do with inherent limitations that may exist in the information collected. At some point, no technology or analysis will help you further. Considering whether the right data exists is critical at the early project stage. You may want to create contingencies to pivot towards collecting better data to answer the question. Or, if the data simply does not exist or is impractical to collect, revert to the original question of interest and redefine the project scope. This is about aligning expectations and gets to why the project was initiated in the first place.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/03-scoping/what-if-we-dont-have-the-right-data.adoc/"},{value:"What if we don’t like the results?",label:"<p>This is when the results of the project are not those anticipated by the end user. This can be a function of not having the right data, poor model inputs or poor model predictions in specific scenarios. The possibility that the project might lead to poor results should be discussed among the project stakeholders. This addresses differences in how individuals might accept the results of the project and reveal inherent biases individuals might have. This avoids initiating a project where you already know there’s only one acceptable result. </p>",url:"https://unicef.github.io/ooi-toolkit-ds/03-scoping/what-if-we-dont-like-the-results.adoc/"},{value:"When is the project over?",label:"<p>This is about aligning expectations and gets to why the project was initiated in the first place. Think about what the final deliverable is and work iteratively backward. Gather stakeholder input and identify reasons the project could end. Setting aside obvious failures, such as lack of funding or losing interest, focus should be on the needs to be delivered and how to conclude the project. Many projects will require ongoing support and maintenance, but this should be clarified up front. The answer to when the project is over shouldn’t be assumed, until asked.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/03-scoping/when-is-the-project-over.adoc/"},{value:"Who does the problem affect?",label:"<p>This is about identifying the end users. Identify the people who will be affected by the problem and incorporate them into the discussion of problem articulation. This can mean small group or focus group discussions if they are representative of a larger group of people. Understand how these people will be affected by the project. One approach to think about this is to have a solution trial run. Assuming you can answer the problem, ask yourself if you can use the answer and whose life will change as a result.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/03-scoping/who-does-the-problem-affect.adoc/"},{value:"Why is the problem important?",label:"<p>This section is about problem definition. This sets the expectations for why a project should be undertaken in the first place. Identifying the importance of the problem before starting will help optimize how company resources are used. Relatedly, you will want to answer:\n Why does this problem matter? Is this a new problem or has it been solved already?  In this effort, you will want to engage with the different collaborators, both technical and non-technical, to understand how each person sees the problem. This is important to create alignment and support for the project to solve the problem.\nTechnology should not be included in defining the problem. Too much focus on methodology (i.e., some new analytical method or technology) or on deliverables (i.e., interactive dashboard, etc) can derail from the actual business problem. The problem should be articulated in a direct, clear language that everyone can understand. Think carefully about the problem to be solved as opposed to the technology to be used.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/03-scoping/why-is-the-problem-important.en.adoc/"}];$("#search").autocomplete({source:e}).data("ui-autocomplete")._renderItem=function(t,e){return $("<li>").append("<a href="+e.url+' + " &quot;" +  >'+e.value+"</a>"+e.label).appendTo(t)}})</script></div></div></div></div></header><script>remSpace()</script><script>function remSpace(){document.getElementById("section").style.paddingTop="3rem"}</script><section class=section><div class=container><div class="row justify-content-center"><div class="col-12 text-center"><h2 class=section-title>Find your answer by subject</h2></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-eye icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Data Collection and Processing</h3><p class=mb-0>Considerations in data collection and data processing</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-governance.en.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Data Governance</h3><p class=mb-0>Matters of data governance</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-preprocessing.en.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Data Pre-processing</h3><p class=mb-0>What is data pre-processing about?</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-quality.en.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Data Quality</h3><p class=mb-0>Data quality concerns</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/01-definitions/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Definitions</h3><p class=mb-0>Definitions of the terminology used in this toolkit</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/feature-engineering.en.adoc-copy/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Feature Engineering</h3><p class=mb-0>What is feature engineering and considerations in performing feature engineering</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/02-machine-learning-lifecycle/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Machine Learning Lifecycle</h3><p class=mb-0>Key aspects of the machine learning project lifecycle</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/missing-data.en.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Missing Data</h3><p class=mb-0>What is the nature of missing data? How to consider handling missing data?</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/03-scoping/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-eye icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Scoping</h3><p class=mb-0>Deciding on the objectives of the project. What makes a good candidate for a machine learning or artificial intelligence application</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/03-scoping/what-if-we-dont-have-the-right-data.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">What if we don’t have the right data to solve the problem?</h3><p class=mb-0>Data limitations in the data collected to solve a problem</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/03-scoping/what-if-we-dont-like-the-results.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">What if we don’t like the results?</h3><p class=mb-0>Reacting to poor results</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/03-scoping/when-is-the-project-over.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">When is the project over?</h3><p class=mb-0>Aligning project expectations</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/03-scoping/who-does-the-problem-affect.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Who does the problem affect?</h3><p class=mb-0>Identifying the end users</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/03-scoping/why-is-the-problem-important.en.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Why is the problem important?</h3><p class=mb-0>Defining the problem</p></a></div></div></div></section><footer class="section bg-primary p-4 mt-5"><div class=container><div class="row align-items-center"><div class="col-md-3 text-md-left text-center"><ul><li><a class="nav-link text-white" href=/ooi-toolkit-ds>HOME</a></li><li class=nav-item><a class="nav-link text-white text-uppercase" href=https://unicef.github.io/ooi-toolkit-ds/faq>FAQ</a></li><li class=nav-item><a class="nav-link text-white text-uppercase" href=https://unicef.github.io/ooi-toolkit-ds/>Toolkits</a></li></ul></div><div class="col-md-6 text-md-center text-center"><p class="mb-md-0 mb-4 text-white">A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation.</p></div><div class="col-md-3 text-md-right text-center"><ul class=text-white><li class=nav-item><a class="nav-link text-white font-weight-bold" href=https://www.unicef.org/>UNICEF Global</a></li><li class=nav-item><a class="nav-link text-white font-weight-bold" href=https://www.unicefinnovationfund.org/>UNICEF Venture Fund</a></li><li class=nav-item><a class="nav-link text-white font-weight-bold" href=https://www.unicef.org/legal>Legal</a><p class="h6 text-md-right font-weight-light">Find legal information and policies related to UNICEF Global's digital communications.</p></li></ul><ul class=list-inline><li class=list-inline-item><a class="text-color d-inline-block p-2 text-white" href=https://github.com/unicef/ooi-toolkit-ds aria-label="UNICEF Data Science & Artificial Intelligence Toolkit on GitHub"><i class=ti-github></i></a></li><li class=list-inline-item><a class="text-color d-inline-block p-2 text-white" href=https://twitter.com/UNICEFinnovate aria-label="@UNICEFinnovate on Twitter"><i class=ti-twitter></i></a></li></ul></div></div></div><p class="text-md-center text-center text-white mt-3 h6 font-italic">Creative Commons BY-SA 4.0. Site theme adapted from UNICEF Inventory theme.</p></footer><script src=https://unicef.github.io/ooi-toolkit-ds/js/script.min.js></script></body></html>