<!doctype html><html lang=en-us><head><meta charset=utf-8><title>UNICEF Data Science & A.I. Toolkit</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.96.0"><meta name=description content="UNICEF Data Science & A.I. Toolkit - UNICEF Data Science & A.I. Toolkit "><link rel=stylesheet href=https://unicef.github.io/ooi-toolkit-ds/plugins/bootstrap/bootstrap.min.css><link rel=stylesheet href=https://unicef.github.io/ooi-toolkit-ds/plugins/themify-icons/themify-icons.css><link rel=stylesheet href=https://unicef.github.io/ooi-toolkit-ds/plugins/drone-dpgtoolkit-icons/icons.css><link rel=icon href=https://unicef.github.io/ooi-toolkit-ds/images/favicon.png type=image/x-icon><link href="https://fonts.googleapis.com/css?family=Open%2bSans:300,400,700&display=swap" rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.9.359/pdf.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.9.3/html2pdf.bundle.js></script>
<script src=https://kit.fontawesome.com/9196e0632a.js crossorigin=anonymous></script><style>:root{--primary-color:#1CABE2;--body-color:#D8D1C9;--text-color:#777779;--text-color-dark:#374EA2;--text-title-color:#ffffff;--white-color:#ffffff;--light-color:#f8f9fa;--font-family:Open+Sans}</style><link href=https://unicef.github.io/ooi-toolkit-ds/css/style.min.css rel=stylesheet media=screen><script src=https://unicef.github.io/ooi-toolkit-ds/plugins/jquery/jquery-1.12.4.js></script>
<script src=https://unicef.github.io/ooi-toolkit-ds/plugins/jquery/jquery-ui.js></script>
<script src=https://unicef.github.io/ooi-toolkit-ds/plugins/bootstrap/bootstrap.min.js></script>
<script src=https://unpkg.com/@popperjs/core@2></script>
<script src=https://unicef.github.io/ooi-toolkit-ds/plugins/match-height/jquery.matchHeight-min.js></script><meta name=twitter:title content="UNICEF Data Science & A.I. Toolkit"><meta name=twitter:description content="A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation."><meta property="og:title" content="UNICEF Data Science & A.I. Toolkit"><meta property="og:description" content="A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation."><meta property="og:type" content="website"><meta property="og:url" content="https://unicef.github.io/ooi-toolkit-ds/"><meta name=twitter:card content="summary"><meta name=twitter:title content="UNICEF Data Science & A.I. Toolkit"><meta name=twitter:description content="A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation."></head><body><header class="banner overlay bg-cover" data-background=https://unicef.github.io/ooi-toolkit-ds/images/banner.jpg><nav class="navbar navbar-expand-md navbar-dark" style=background-color:transparent><div class="container px-2 px-md-0 navigation-bar"><div id=site-brand><a class="navbar-brand px-2" href=https://www.unicef.org/><div class=text-center><img class="img-fluid d-inline" src=https://unicef.github.io/ooi-toolkit-ds/images/unicef-logo.png alt="UNICEF Data Science & A.I. Toolkit"> <a class="text-white d-block" href=/ooi-toolkit-ds>UNICEF Data Science & A.I. Toolkit</a></div></a></div><button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation aria-controls=navigation aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse text-center" id=navigation><ul class="navbar-nav ml-auto"><li class=nav-item><a class="nav-link text-white" href=https://unicef.github.io/ooi-toolkit-ds/faq>FAQ</a></li><li class=nav-item><a class="nav-link text-white" href=https://unicef.github.io/ooi-toolkit-ds/pages>pages</a></li></ul></div></div><p class="text-white unicef-glob mx-3">Visit <a href=https://www.unicef.org/ class=text-white>UNICEF Global <i class="fas fa-angle-double-right"></i></a></p></nav><div class="container section"><div class=row><div class="col-lg-8 text-center mx-auto"><h1 class="text-white mb-3">UNICEF Data Science & A.I. Toolkit</h1><p class="text-white mb-4">A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation.</p><div class=position-relative><input id=search class=form-control placeholder="Have a question? Search the site here.">
<i class="ti-search search-icon"></i>
<script>$(function(){var e=[{value:"Alerts",label:"<p></p>",url:"https://unicef.github.io/ooi-toolkit-ds/alerts/"},{value:"Categories",label:"<p></p>",url:"https://unicef.github.io/ooi-toolkit-ds/categories/"},{value:"Data Collection and Processing",label:"<p>This toolkit will draw on considerations in data collection and processing for your data science project.\nData science naturally relies on collecting data from some source. Typically, data is generated by human activity, such as logs of activity on a web platform (for e.g., clicks, score records, etc.), recorded events (for e.g., visits to medical facilities, attendance at school, etc.), text scripts, visual images or audio recordings. Most data generated in this way is typically observational whereby the data collector has no control over the data generating process that occurs in the real world. Observational data is collected based on what is seen or heard by people or a computer passively observing some process.\nData can also be experimental, whereby data is collected in a controlled environment following a scientific method. Experimental data is not passively collected, but rather it is collected methodically to answer a specific question typically in a controlled setting. In experimental settings, a group of people or things are randomly assigned to treatment and control groups. For example, in drug trials, a treatment group is given some dosage of a drug, while a control group would be assigned a placebo. Experiments lend themselves best to cause-and-effect studies because assigned to treatment and control are randomized and therefore, latent confounding factors that might differentiate the groups can be controlled or explicitly identified. In contrast, cause-and-effect claims cannot be made readily with observational data unless all explicit and latent factors can be controlled for and there is some source of external source of variation that can be attributed directly to the effect (a challenging analytical task).1 Controlled experiments of this type are often used in A/B testing and user design testing.\nAnother consideration is whether the data is structured or unstructured. Structured data has a sense of order and is typically in a row-column structured framework such as spreadsheets or database tables. Unstructured data can be images, text scripts or audio files. Unstructured data can require additional processing to convert their attributes into structured data format for analysis methods.\nAttribution: 1Gerber, Alan S., and Donald P. Green. Field Experiments: Design, Analysis, and Interpretation. W.W. Norton, 2012.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/"},{value:"Data Governance",label:"<p>Data governance is a critical component of a sustainable and scalable AI project. Data governance is defined as a collection of processes, roles, policies, standards and metrics that ensure the effective and efficient use of information. Good data governance establishes processes and responsibilities ensuring data quality and security. Essentially, data governance defines who can act on the data, upon what data, in which situations and with what methods.\nAttribution:\nEvren Eryurek, et al. Data Governance: The Definitive Guide: People, Processes, and Tools to Operationalize Data Trustworthiness. O’Reilly Media, 2021.\nBuilding a data governance framework - Talend Data Integration. Talend. (n.d.). Retrieved from https://www.talend.com/resources/building-data-governance-framework/\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-governance.en.adoc/"},{value:"Data Pre-processing",label:"<p>Data pre-processing has to do with the process of managing, analyzing, filtering, transforming, encoding and preparing data to be usefully processed by the machine. This is typically one of the most time-consuming aspects of the data science process. Any decisions made by the data scientist in the data pre-processing stage can have important impacts in subsequent model development and, even, deployment stages. Therefore, it is important to document analytical decisions made in this stage, whether in the code or through a documenting tool, to trace the lineage of the data from the original data source, when the data is in its raw form, to the model training and development stage.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-preprocessing.en.adoc/"},{value:"Data Quality",label:"<p>Data quality is a critical concern for AI projects. Poor data quality can bias prediction results and mislead users. There are six key areas of data quality:\nAccuracy: how well does the data reflect reality?\nCompleteness: is the data comprehensive or not missing value entries in unexpected instances?\nConsistency: does information stored in one place match the information stored in another place?\nTimeliness: is data available when needed?\nValidity: is data in a specific format? Is it an unusable format? Does it follow business rules?\nUniqueness: Is the data instance the only instance in which the data appears in the sample?\nAttribution:\nSarfin, R. L., \u0026amp; Editor, P. (2021, May 12). Data Quality Dimensions: How do you measure up? (\u002b free scorecard). Precisely. Retrieved from https://www.precisely.com/blog/data-quality/data-quality-dimensions-measure\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-quality.en.adoc/"},{value:"Definitions",label:"<p>It is important to start with some definitions of the terminology used in this toolkit.\n\u0026laquo;\u0026laquo;\u0026laquo;\u0026lt; HEAD Data science is broadly defined as a craft or set of activities that involves working with large amounts of data, grappling with computational problems introduced by structure, size, messiness such as missing data, and the complexity of data, while attempting to solve a real-world problem. Product-oriented data science deals with everything from the data engineering and infrastructure for data collection and logging, to privacy considerations, to decisions around what data is user-facing, how and which data will be used to inform decisions, and how the data will be built back into the product.1\nArtificial intelligence (AI) is broadly defined as an effort to automate intellectual tasks normally performed by human beings. AI includes machine learning and deep learning as well as approaches that do not involve any learning. Symbolic AI, for example, is premised on the ability of programmers to hard code a sufficiently large number of rules for manipulating knowledge (this is also known as expert systems). Symbolic AI can serve well for logical, well-defined problems.2 Data science is broadly defined as a craft or set of activities that involves working with large amounts of data, grappling with computational problems introduced by structure, size, messiness such as missing data, and the complexity of data, while attempting to solve a real-world problem. Product-oriented data science deals with everything from the data engineering and infrastructure for data collection and logging, to privacy considerations, to decisions around what data is user-facing, how and which data will be used to inform decisions, and how the data will be built back into the product.1\nArtificial intelligence (AI) is broadly defined as an effort to automate intellectual tasks normally performed by human beings. AI includes machine learning and deep learning as well as approaches that do not involve any learning. Symbolic AI, for example, is premised on the ability of programmers to hard code a sufficiently large number of rules for manipulating knowledge (this is also known as expert systems). Symbolic AI can serve well for logical, well-defined problems.2\n       main\n       Machine learning (ML) is better suited for more complex and intractable problems, such as image classification, speech recognition, language translation and probabilistic anomaly detection. Machine learning is a subset of AI where data can be used to train computers to detect patterns and mimic human decision-making. A machine-learning system is trained rather than explicitly programmed. It’s presented with many examples relevant to a task, and it finds statistical structure in these examples that eventually allows the system to come up with rules for automating the task. Machine learning involves using algorithms to detect patterns in data and then use those learned patterns to predict an outcome on new data. Generally, this involves an iterative process and allows the machine learning system to determine predictions without being explicitly programmed.\nDeep learning is a subset of ML that can process a wider range of data resources including text, images and audio clips and typically requires less data preprocessing by humans. The “deep” part refers to learning successive layers of increasingly meaningful representations all learned from training data. The depth refers to the number of layers that contribute to a model of the data. In contrast, other approaches to machine learning tend to focus on learning only one or two layers of representations of the data; hence, they’re sometimes called shallow learning. In common-speak, the application of neural networks models refers to deep learning.\nNatural Language Processing (NLP) heavily leverages Machine Learning as well as Deep Learning to allow computers to interact with humans in their own natural language whether written or oral. NLP applications attempt to understand natural human communication, either written or spoken, and communicate in return with us using similar, natural language.\nRobotic Process Automation (RPA) is a type of automation that mimics the activity of a human when they carry out a structured, repetitive task or process, little judgement. It is generally rule based, can’t learn outside parameters, so not considered AI; however, RPA can be built with learning modules on complex tasks.\nFigure 1 diagram below depicts the AI ecosystem and the relationship between AI, ML, Deep Learning, NLP and RPA.\nFootnotes\n1 Schutt, Rachel, and Cathy O\u0026rsquo;Neil. Doing Data Science: Straight Talk from the Frontline. O\u0026rsquo;Reilly, 2013.\n2 Chollet François. Deep Learning with Python. Manning Publications, 2021.\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/01-definitions/"},{value:"DownloadBtn",label:"<p></p>",url:"https://unicef.github.io/ooi-toolkit-ds/downloadbtn/"},{value:"Feature Engineering",label:"<p>Feature engineering is related to data pre-processing but is more closely related to the modeling process. Feature engineering refers to when model inputs or features are generated that are then incorporated into a model for training. Typically, this means adjusting and reworking the predictors to enable models to better uncover predictor-response relationships. The engineering involves the steps taken to improve model performance by generating the appropriate features. Since we may not know in advance what adjustments or re-adjustments of the features are required to improve model performance, the re-working of predictors can be experimental in nature requiring experience and tools to find predictor representations.\nFeature engineering can involve scaling (to scale numerical features so that they are in the same numerical scale) through standardization or normalization. Normalization involves mean scaling where the mean value of a particular feature is subtracted from each feature value. Standardization involves variance scaling where each feature has a mean value of zero and standard deviation of one.\nIf a feature can take on many values, it can be normalized with buckets. For example, if a feature is real-valued, ordinal, or integer valued, the values can be arranged into several different buckets. In some cases, features can be encoded into binary values (0 or 1, “Yes” or “No”, null or not null). The latter is typically the case with text features.\nAttribution:\nJohnson, K. and Max Kuhn. (2019, June 21). Feature engineering and selection: A practical approach for predictive models. Feature Engineering and Selection: A Practical Approach for Predictive Models. Retrieved from http://www.feat.engineering/\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/feature-engineering.en.adoc-copy/"},{value:"Machine Learning Lifecycle",label:"<p>This toolkit will emphasize the key aspects of the machine learning project lifecycle. This starts with scoping (defining the project), data collection and organization, model development and model deployment.\nFigure 2. The Machine Learning Lifecycle\nMachine learning projects typically start with scoping or defining the project. This includes deciding on the objectives of the project and what makes it a good candidate for a machine learning application.\nThen, it is defining the data and establishing a baseline. For example, if we can accurately predict an outcome 50% of the time just by flipping a coin, a model should, at least, do better than that. Features should be engineered attuned to the underlying characteristics of the data (for instance, different treatment of categorical versus numerical data types) and business-specific features related to the defined problem. Often, data exploration and data mining inform the data scientist about the features to craft. Moreover, we should ensure the data is labeled consistently in the case of a supervised learning problem.\nThe modeling process involves selecting an algorithm or model framework (what algorithmic framework makes sense for the problem and data at hand) and training the model to learn the representations in the input data that get us closer to the output data. Error analysis is performed to evaluate and improve the model. Typically, the model that best minimizes the error is selected for deployment. Often, modeling informs us about issues in the data organization and labeling, leading us to go back and fix issues in the data.\nDeployment is typically the final step in the process. Once the model is selected, and it is put into production, it should be continually monitored through error analysis and the entire system should be maintained to detect any changes in the underlying data distribution serving as inputs to the model. Over time, it is common for machine learning models to require maintenance and retraining (reverting back to model development and then re-deployed).\nAttribution\nNg, Andrew \u0026amp; Cristian Bartolomé Arámburu (n.d.). Introduction to Machine Learning in Production [MOOC]. Coursera DeepLearning.AI. https://www.coursera.org/learn/introduction-to-machine-learning-in-production\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/02-machine-learning-lifecycle/"},{value:"Missing Data",label:"<p>Handling missing values can be a component of data pre-processing as well as feature engineering. Missing values can occur for several reasons including structural deficiencies in the data (namely, deliberate omission in the data collection or data generating process), random occurrences, or specific reasons.\nA structural deficiency would be the case of a missing component of a predictor omitted from the data. Typically, these cases could be resolved once the necessary component is identified. For example, if a hypothetical dataset has some predictor variable where values are either “A” or “B” or missing, where most values are missing, it may be tempting to discard the predictor variable due to the high rate of missingness. However, discarding this predictor variable may inadvertently be throwing away valuable information since missing can be interpreted to mean not being “A” or “B”. A better recording of the predictor variable may be to replace the missing values with “Not A or B”.\nAnother reason for missing values may be due to random occurrences. This can be occurrences missing completely at random (“MCAR”) where the likelihood of a missing value is equal for all data points, both observed and unobserved. Missing values can be interpreted here as independent of the data generating process. This can also be an occurrence missing at random (“MAR”) where the likelihood of a missing value is not equal for all data points. In this case, the probability of a missing value depends on the observed data, but not unobserved data.\nA third reason for missingness can be due to specific reasons or missing not at random (“MNAR”). This often occurs in cross-sectional time series data where the same unit of observation (for example, patient in medical trial) drops out of a study. Measurements for this unit of observation will stop after dropping out of the study. The MNAR cases are difficult to handle in practice and data practitioners should seek to understand the nature of the missingness before applying a technique to correct for missingness since a misdiagnosis of missingness could lead to bias in model inference.\nAttribution:\nJohnson, K. and Max Kuhn. (2019, June 21). Feature engineering and selection: A practical approach for predictive models. Feature Engineering and Selection: A Practical Approach for Predictive Models. Retrieved from http://www.feat.engineering/\n</p>",url:"https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/missing-data.en.adoc/"},{value:"UNICEF Data Science \u0026 A.I. Toolkit",label:"<p></p>",url:"https://unicef.github.io/ooi-toolkit-ds/"}];$("#search").autocomplete({source:e}).data("ui-autocomplete")._renderItem=function(t,e){return $("<li>").append("<a href="+e.url+' + " &quot;" +  >'+e.value+"</a>"+e.label).appendTo(t)}})</script></div></div></div></div></header><script>remSpace()</script><script>function remSpace(){document.getElementById("section").style.paddingTop="3rem"}</script><section class=section><div class=container><div class="row justify-content-center"><div class="col-12 text-center"><h2 class=section-title>Find your answer by subject</h2></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-eye icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Data Collection and Processing</h3><p class=mb-0>Considerations in data collection and data processing</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-governance.en.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Data Governance</h3><p class=mb-0>Matters of data governance</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-preprocessing.en.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Data Pre-processing</h3><p class=mb-0>What is data pre-processing about?</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/data-quality.en.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Data Quality</h3><p class=mb-0>Data quality concerns</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/01-definitions/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Definitions</h3><p class=mb-0>Definitions of the terminology used in this toolkit</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/feature-engineering.en.adoc-copy/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Feature Engineering</h3><p class=mb-0>What is feature engineering and considerations in performing feature engineering</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/02-machine-learning-lifecycle/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Machine Learning Lifecycle</h3><p class=mb-0>Key aspects of the machine learning project lifecycle</p></a></div><div class="col-lg-4 col-sm-6 mb-4"><a href=https://unicef.github.io/ooi-toolkit-ds/04-data-collection-processing/missing-data.en.adoc/ class="px-4 py-5 bg-white shadow text-center d-block match-height cardLink"><i class="ti-search icon text-primary d-block mb-4"></i><h3 class="mb-3 mt-0">Missing Data</h3><p class=mb-0>What is the nature of missing data? How to consider handling missing data?</p></a></div></div></div></section><footer class="section bg-primary p-4 mt-5"><div class=container><div class="row align-items-center"><div class="col-md-3 text-md-left text-center"><ul><li><a class="nav-link text-white" href=/ooi-toolkit-ds>HOME</a></li><li class=nav-item><a class="nav-link text-white text-uppercase" href=https://unicef.github.io/ooi-toolkit-ds/faq>FAQ</a></li></ul></div><div class="col-md-6 text-md-center text-center"><p class="mb-md-0 mb-4 text-white">A toolkit for data science and AI modeling best practices, created for the UNICEF Venture Fund in the Office of Innovation.</p></div><div class="col-md-3 text-md-right text-center"><ul class=text-white><li class=nav-item><a class="nav-link text-white font-weight-bold" href=https://www.unicef.org/>UNICEF Global</a></li><li class=nav-item><a class="nav-link text-white font-weight-bold" href=https://www.unicefinnovationfund.org/>UNICEF Venture Fund</a></li><li class=nav-item><a class="nav-link text-white font-weight-bold" href=https://www.unicef.org/legal>Legal</a><p class="h6 text-md-right font-weight-light">Find legal information and policies related to UNICEF Global's digital communications.</p></li></ul><ul class=list-inline><li class=list-inline-item><a class="text-color d-inline-block p-2 text-white" href=https://github.com/unicef/ooi-toolkit-ds aria-label="UNICEF Data Science & Artificial Intelligence Toolkit on GitHub"><i class=ti-github></i></a></li><li class=list-inline-item><a class="text-color d-inline-block p-2 text-white" href=https://twitter.com/UNICEFinnovate aria-label="@UNICEFinnovate on Twitter"><i class=ti-twitter></i></a></li></ul></div></div></div><p class="text-md-center text-center text-white mt-3 h6 font-italic">Creative Commons BY-SA 4.0. Site theme adapted from UNICEF Inventory theme.</p></footer><script src=https://unicef.github.io/ooi-toolkit-ds/js/script.min.js></script></body></html>